{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "# 优化超参数\r\n",
        "\r\n",
        "有许多机器学习算法需要超参数（影响训练但无法通过训练数据本身确定的参数值）。例如，训练逻辑回归模型时，可以使用正则化率超参数来抵消模型中的偏差；或者训练卷积神经网络时，可以使用学习速率和批大小等超参数来分别控制权重的调整方式以及以小批量方式处理的数据项数量。超参数值的选择会显著影响已训练模型的性能或训练该模型所需的时间；通常需要尝试多种组合以找到最佳解决方案。\r\n",
        "\r\n",
        "在本例中，你将使用两个超参数训练分类模型，但是原则适用于可使用 Azure 机器学习训练的任何类型的模型。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "## 连接到工作区\r\n",
        "\r\n",
        "首先，请连接到你的工作区。\r\n",
        "\r\n",
        "> **备注**：如果尚未与 Azure 订阅建立经过身份验证的会话，则系统将提示你通过执行以下操作进行身份验证：单击链接，输入验证码，然后登录到 Azure。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import azureml.core\n",
    "from azureml.core import Workspace\n",
    "\n",
    "# Load the workspace from the saved config file\n",
    "ws = Workspace.from_config()\n",
    "print('Ready to use Azure ML {} to work with {}'.format(azureml.core.VERSION, ws.name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "## 准备数据\r\n",
        "\r\n",
        "在本实验室中，你将使用包含糖尿病患者详细信息的数据集。运行以下单元格以创建此数据集（如果已有此数据集，则会采用现有数据集）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Dataset\n",
    "\n",
    "default_ds = ws.get_default_datastore()\n",
    "\n",
    "if 'diabetes dataset' not in ws.datasets:\n",
    "    default_ds.upload_files(files=['./data/diabetes.csv', './data/diabetes2.csv'], # Upload the diabetes csv files in /data\n",
    "                        target_path='diabetes-data/', # Put it in a folder path in the datastore\n",
    "                        overwrite=True, # Replace existing files of the same name\n",
    "                        show_progress=True)\n",
    "\n",
    "    #Create a tabular dataset from the path on the datastore (this may take a short while)\n",
    "    tab_data_set = Dataset.Tabular.from_delimited_files(path=(default_ds, 'diabetes-data/*.csv'))\n",
    "\n",
    "    # Register the tabular dataset\n",
    "    try:\n",
    "        tab_data_set = tab_data_set.register(workspace=ws, \n",
    "                                name='diabetes dataset',\n",
    "                                description='diabetes data',\n",
    "                                tags = {'format':'CSV'},\n",
    "                                create_new_version=True)\n",
    "        print('Dataset registered.')\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "else:\n",
    "    print('Dataset already registered.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "## 准备训练脚本\r\n",
        "\r\n",
        "我们现在来为将用于训练模型的训练脚本创建一个文件夹。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "experiment_folder = 'diabetes_training-hyperdrive'\n",
    "os.makedirs(experiment_folder, exist_ok=True)\n",
    "\n",
    "print('Folder ready.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "现在创建 Python 脚本以训练模型。在本例中，你将使用梯度提升算法训练分类模型。脚本必须包括：\r\n",
        "\r\n",
        "- 你想要优化的每个超参数的参数（在本例中即梯度提升算法的学习速率和估算器数量）\r\n",
        "- 用于记录要优化的性能指标的代码（在本例中将记录 AUC 和准确度，以便可以选择针对其中一项优化模型）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $experiment_folder/diabetes_training.py\n",
    "# Import libraries\n",
    "import argparse, joblib, os\n",
    "from azureml.core import Run\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "\n",
    "# Get the experiment run context\n",
    "run = Run.get_context()\n",
    "\n",
    "# Get script arguments\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "# Input dataset\n",
    "parser.add_argument(\"--input-data\", type=str, dest='input_data', help='training dataset')\n",
    "\n",
    "# Hyperparameters\n",
    "parser.add_argument('--learning_rate', type=float, dest='learning_rate', default=0.1, help='learning rate')\n",
    "parser.add_argument('--n_estimators', type=int, dest='n_estimators', default=100, help='number of estimators')\n",
    "\n",
    "# Add arguments to args collection\n",
    "args = parser.parse_args()\n",
    "\n",
    "# Log Hyperparameter values\n",
    "run.log('learning_rate',  np.float(args.learning_rate))\n",
    "run.log('n_estimators',  np.int(args.n_estimators))\n",
    "\n",
    "# load the diabetes dataset\n",
    "print(\"Loading Data...\")\n",
    "diabetes = run.input_datasets['training_data'].to_pandas_dataframe() # Get the training data from the estimator input\n",
    "\n",
    "# Separate features and labels\n",
    "X, y = diabetes[['Pregnancies','PlasmaGlucose','DiastolicBloodPressure','TricepsThickness','SerumInsulin','BMI','DiabetesPedigree','Age']].values, diabetes['Diabetic'].values\n",
    "\n",
    "# Split data into training set and test set\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)\n",
    "\n",
    "# Train a Gradient Boosting classification model with the specified hyperparameters\n",
    "print('Training a classification model')\n",
    "model = GradientBoostingClassifier(learning_rate=args.learning_rate,\n",
    "                                   n_estimators=args.n_estimators).fit(X_train, y_train)\n",
    "\n",
    "# calculate accuracy\n",
    "y_hat = model.predict(X_test)\n",
    "acc = np.average(y_hat == y_test)\n",
    "print('Accuracy:', acc)\n",
    "run.log('Accuracy', np.float(acc))\n",
    "\n",
    "# calculate AUC\n",
    "y_scores = model.predict_proba(X_test)\n",
    "auc = roc_auc_score(y_test,y_scores[:,1])\n",
    "print('AUC: ' + str(auc))\n",
    "run.log('AUC', np.float(auc))\n",
    "\n",
    "# Save the model in the run outputs\n",
    "os.makedirs('outputs', exist_ok=True)\n",
    "joblib.dump(value=model, filename='outputs/diabetes_model.pkl')\n",
    "\n",
    "run.complete()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "## 创建计算\r\n",
        "\r\n",
        "超参数优化包括使用不同的超参数值运行多个训练迭代，并比较结果模型的性能指标。为了有效地做到这一点，我们将借助按需云计算并创建一个群集，这样即可同时运行多个训练迭代。\r\n",
        "\r\n",
        "使用以下代码指定一个 Azure 机器学习计算群集（如果不存在，则会创建该群集）。\r\n",
        "\r\n",
        "> **重要提示**：在运行以下代码之前，请先将代码中的 *your-compute-cluster* 更改为你的计算群集的名称！群集名称必须是长度在 2 到 16 个字符之间的全局唯一名称。有效字符是字母、数字和 - 字符。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core.compute import ComputeTarget, AmlCompute\n",
    "from azureml.core.compute_target import ComputeTargetException\n",
    "\n",
    "cluster_name = \"your-compute-cluster\"\n",
    "\n",
    "try:\n",
    "    # Check for existing compute target\n",
    "    training_cluster = ComputeTarget(workspace=ws, name=cluster_name)\n",
    "    print('Found existing cluster, use it.')\n",
    "except ComputeTargetException:\n",
    "    # If it doesn't already exist, create it\n",
    "    try:\n",
    "        compute_config = AmlCompute.provisioning_configuration(vm_size='STANDARD_DS11_V2', max_nodes=2)\n",
    "        training_cluster = ComputeTarget.create(ws, cluster_name, compute_config)\n",
    "        training_cluster.wait_for_completion(show_output=True)\n",
    "    except Exception as ex:\n",
    "        print(ex)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "> **备注**：计算实例和群集是基于标准的 Azure 虚拟机映像。对于本练习，建议使用 *Standard_DS11_v2* 映像来实现成本和性能的最佳平衡。如果你的订阅配额不包含此映像，请选择其他映像；但请记住，较大的映像可能会产生更高的成本，但较小的映像可能不够完成任务。或者，可以请 Azure 管理员扩展你的配额。\r\n",
        "\r\n",
        "你需要在计算上托管 Python 环境，因此我们将其定义为 Conda 配置文件。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile $experiment_folder/hyperdrive_env.yml\n",
    "name: batch_environment\n",
    "dependencies:\n",
    "- python=3.6.2\n",
    "- scikit-learn\n",
    "- pandas\n",
    "- numpy\n",
    "- pip\n",
    "- pip:\n",
    "  - azureml-defaults\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "## 运行超参数优化试验\r\n",
        "\r\n",
        "Azure 机器学习包括通过 *Hyperdrive* 试验提供的超参数优化功能。这些试验启动了多个子运行，每个子运行都有不同的超参数组合。可以确定生成最佳模型的运行（由要优化的记录目标性能指标确定），并选择其训练后的模型进行注册和部署。\r\n",
        "\r\n",
        "> **备注**：在本例中，我们没有采用早停法。只有当训练脚本执行多个训练迭代，记录每个迭代的主要指标时，早停法才有作用。这种方法通常用于多次迭代的深度神经网络模型训练。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Experiment, ScriptRunConfig, Environment\n",
    "from azureml.train.hyperdrive import GridParameterSampling, HyperDriveConfig, PrimaryMetricGoal, choice\n",
    "from azureml.widgets import RunDetails\n",
    "\n",
    "# Create a Python environment for the experiment\n",
    "hyper_env = Environment.from_conda_specification(\"experiment_env\", experiment_folder + \"/hyperdrive_env.yml\")\n",
    "\n",
    "# Get the training dataset\n",
    "diabetes_ds = ws.datasets.get(\"diabetes dataset\")\n",
    "\n",
    "# Create a script config\n",
    "script_config = ScriptRunConfig(source_directory=experiment_folder,\n",
    "                                script='diabetes_training.py',\n",
    "                                # Add non-hyperparameter arguments -in this case, the training dataset\n",
    "                                arguments = ['--input-data', diabetes_ds.as_named_input('training_data')],\n",
    "                                environment=hyper_env,\n",
    "                                compute_target = training_cluster)\n",
    "\n",
    "# Sample a range of parameter values\n",
    "params = GridParameterSampling(\n",
    "    {\n",
    "        # Hyperdrive will try 6 combinations, adding these as script arguments\n",
    "        '--learning_rate': choice(0.01, 0.1, 1.0),\n",
    "        '--n_estimators' : choice(10, 100)\n",
    "    }\n",
    ")\n",
    "\n",
    "# Configure hyperdrive settings\n",
    "hyperdrive = HyperDriveConfig(run_config=script_config, \n",
    "                          hyperparameter_sampling=params, \n",
    "                          policy=None, # No early stopping policy\n",
    "                          primary_metric_name='AUC', # Find the highest AUC metric\n",
    "                          primary_metric_goal=PrimaryMetricGoal.MAXIMIZE, \n",
    "                          max_total_runs=6, # Restict the experiment to 6 iterations\n",
    "                          max_concurrent_runs=2) # Run up to 2 iterations in parallel\n",
    "\n",
    "# Run the experiment\n",
    "experiment = Experiment(workspace=ws, name='mslearn-diabetes-hyperdrive')\n",
    "run = experiment.submit(config=hyperdrive)\n",
    "\n",
    "# Show the status in the notebook as the experiment runs\n",
    "RunDetails(run).show()\n",
    "run.wait_for_completion()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "可在上面的小组件中查看试验运行状态。还可以在 [Azure 机器学习工作室](https://ml.azure.com)中查看主要的 Hyperdrive 试验运行及其子运行。\r\n",
        "\r\n",
        "> **备注**：如果系统显示了一条表示不能显示非数值内容的消息，可以忽略它。\r\n",
        "\r\n",
        "## 确定性能最佳的运行\r\n",
        "\r\n",
        "完成所有运行后，可以根据指定的性能指标找到最佳运行（在本例中为具有最佳 AUC 的运行）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all child runs, sorted by the primary metric\n",
    "for child_run in run.get_children_sorted_by_primary_metric():\n",
    "    print(child_run)\n",
    "\n",
    "# Get the best run, and its metrics and arguments\n",
    "best_run = run.get_best_run_by_primary_metric()\n",
    "best_run_metrics = best_run.get_metrics()\n",
    "script_arguments = best_run.get_details() ['runDefinition']['arguments']\n",
    "print('Best Run Id: ', best_run.id)\n",
    "print(' -AUC:', best_run_metrics['AUC'])\n",
    "print(' -Accuracy:', best_run_metrics['Accuracy'])\n",
    "print(' -Arguments:',script_arguments)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "你已找到最佳运行，现在可以注册它所训练的模型。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from azureml.core import Model\n",
    "\n",
    "# Register model\n",
    "best_run.register_model(model_path='outputs/diabetes_model.pkl', model_name='diabetes_model',\n",
    "                        tags={'Training context':'Hyperdrive'},\n",
    "                        properties={'AUC': best_run_metrics['AUC'], 'Accuracy': best_run_metrics['Accuracy']})\n",
    "\n",
    "# List registered models\n",
    "for model in Model.list(ws):\n",
    "    print(model.name, 'version:', model.version)\n",
    "    for tag_name in model.tags:\n",
    "        tag = model.tags[tag_name]\n",
    "        print ('\\t',tag_name, ':', tag)\n",
    "    for prop_name in model.properties:\n",
    "        prop = model.properties[prop_name]\n",
    "        print ('\\t',prop_name, ':', prop)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
        "> **详细信息**：有关 Hyperdrive 的详细信息，请参阅 [Azure ML 文档](https://docs.microsoft.com/azure/machine-learning/how-to-tune-hyperparameters)。"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6 - AzureML",
   "language": "python",
   "name": "python3-azureml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}